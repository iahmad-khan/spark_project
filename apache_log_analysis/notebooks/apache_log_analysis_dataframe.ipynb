{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64.242.88.10 - - [07/Mar/2004:16:05:49 -0800] \"GET /twiki/bin/edit/Main/Double_bounce_sender?topicparent=Main.ConfigurationVariables HTTP/1.1\" 401 12846\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from pyspark import SparkConf, SparkContext ,SQLContext,Row,HiveContext\n",
    "import sys\n",
    "import re\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "conf = SparkConf().setAppName(\"Apache Log Analyzer\")\n",
    "#sc = SparkContext(conf=conf)\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "s='64.242.88.10 - - [07/Mar/2004:16:05:49 -0800] \"GET /twiki/bin/edit/Main/Double_bounce_sender?topicparent=Main.ConfigurationVariables HTTP/1.1\" 401 12846'\n",
    "print (s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Row(64.242.88.10, -, -, 07/Mar/2004:16:05:49 -0800, GET, /twiki/bin/edit/Main/Double_bounce_sender?topicparent=Main.ConfigurationVariables, HTTP/1.1, 401, 12846)>\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Creating a function to read each element using Regex. This module will be passed later on in the notebook.\n",
    "'''\n",
    "def log_line(line):\n",
    "    patrn = '^(\\S+) (\\S+) (\\S+) \\[([\\w:/]+\\s[+\\-]\\d{4})\\] \"(\\S+) (\\S+) (\\S+)\" (\\d{3}) (\\d+)'\n",
    "    mtch = re.search(patrn,line)\n",
    "    if mtch is None:\n",
    "        pass\n",
    "    else :\n",
    "        ip = mtch.group(1)\n",
    "        client = mtch.group(2)\n",
    "        user = mtch.group(3)\n",
    "        date_time = mtch.group(4)\n",
    "        mode = mtch.group(5)\n",
    "        target = mtch .group(6)\n",
    "        protocol = mtch.group(7)\n",
    "        res_code = mtch.group(8)\n",
    "        size = mtch.group(9)\n",
    "        return Row(ip,client,user,date_time,mode,target,protocol,res_code,size)\n",
    "print (log_line(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Row(64.242.88.10, -, -, 07/Mar/2004:16:05:49 -0800, GET, /twiki/bin/edit/Main/Double_bounce_sender?topicparent=Main.ConfigurationVariables, HTTP/1.1, 401, 12846)>,\n",
       " <Row(64.242.88.10, -, -, 07/Mar/2004:16:06:51 -0800, GET, /twiki/bin/rdiff/TWiki/NewUserTemplate?rev1=1.3&rev2=1.2, HTTP/1.1, 200, 4523)>,\n",
       " <Row(64.242.88.10, -, -, 07/Mar/2004:16:10:02 -0800, GET, /mailman/listinfo/hsdivision, HTTP/1.1, 200, 6291)>,\n",
       " <Row(64.242.88.10, -, -, 07/Mar/2004:16:11:58 -0800, GET, /twiki/bin/view/TWiki/WikiSyntax, HTTP/1.1, 200, 7352)>,\n",
       " <Row(64.242.88.10, -, -, 07/Mar/2004:16:20:55 -0800, GET, /twiki/bin/view/Main/DCCAndPostFix, HTTP/1.1, 200, 5253)>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading source file form HDFS and creating RDD\n",
    "\n",
    "logFileRdd = sc.textFile(\"/user/data/apache_log.txt\")\n",
    "logFileRdd.take(5)\n",
    "parseLogFileRdd = logFileRdd.map(log_line).cache()\n",
    "parseLogFileRdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_schema():\n",
    "    schema = StructType(\n",
    "       [\n",
    "        StructField(\"ip\",          StringType(),  False),\n",
    "        StructField(\"client\",      StringType(),  False),\n",
    "        StructField(\"user\",        StringType(),  False),\n",
    "        StructField(\"date_time\",   StringType(),  False),\n",
    "        StructField(\"mode\",        StringType(),  False),\n",
    "        StructField(\"target\",      StringType(),  False),\n",
    "        StructField(\"protocol\",    StringType(),  False),\n",
    "        StructField(\"res_code\",    StringType(),  False),\n",
    "        StructField(\"size\",        StringType(),  False)\n",
    "       ]\n",
    "   )\n",
    "    return schema\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------+----+--------------------+----+--------------------+--------+--------+-----+\n",
      "|          ip|client|user|           date_time|mode|              target|protocol|res_code| size|\n",
      "+------------+------+----+--------------------+----+--------------------+--------+--------+-----+\n",
      "|64.242.88.10|     -|   -|07/Mar/2004:16:05...| GET|/twiki/bin/edit/M...|HTTP/1.1|     401|12846|\n",
      "|64.242.88.10|     -|   -|07/Mar/2004:16:06...| GET|/twiki/bin/rdiff/...|HTTP/1.1|     200| 4523|\n",
      "|64.242.88.10|     -|   -|07/Mar/2004:16:10...| GET|/mailman/listinfo...|HTTP/1.1|     200| 6291|\n",
      "|64.242.88.10|     -|   -|07/Mar/2004:16:11...| GET|/twiki/bin/view/T...|HTTP/1.1|     200| 7352|\n",
      "|64.242.88.10|     -|   -|07/Mar/2004:16:20...| GET|/twiki/bin/view/M...|HTTP/1.1|     200| 5253|\n",
      "|64.242.88.10|     -|   -|07/Mar/2004:16:23...| GET|/twiki/bin/oops/T...|HTTP/1.1|     200|11382|\n",
      "|64.242.88.10|     -|   -|07/Mar/2004:16:24...| GET|/twiki/bin/view/M...|HTTP/1.1|     200| 4924|\n",
      "|64.242.88.10|     -|   -|07/Mar/2004:16:29...| GET|/twiki/bin/edit/M...|HTTP/1.1|     401|12851|\n",
      "|64.242.88.10|     -|   -|07/Mar/2004:16:30...| GET|/twiki/bin/attach...|HTTP/1.1|     401|12851|\n",
      "|64.242.88.10|     -|   -|07/Mar/2004:16:31...| GET|/twiki/bin/view/T...|HTTP/1.1|     200| 3732|\n",
      "|64.242.88.10|     -|   -|07/Mar/2004:16:32...| GET|/twiki/bin/view/M...|HTTP/1.1|     200|40520|\n",
      "|64.242.88.10|     -|   -|07/Mar/2004:16:33...| GET|/twiki/bin/edit/M...|HTTP/1.1|     401|12851|\n",
      "|64.242.88.10|     -|   -|07/Mar/2004:16:35...| GET|/mailman/listinfo...|HTTP/1.1|     200| 6379|\n",
      "|64.242.88.10|     -|   -|07/Mar/2004:16:36...| GET|/twiki/bin/rdiff/...|HTTP/1.1|     200|46373|\n",
      "|64.242.88.10|     -|   -|07/Mar/2004:16:37...| GET|/twiki/bin/view/T...|HTTP/1.1|     200| 4140|\n",
      "|64.242.88.10|     -|   -|07/Mar/2004:16:39...| GET|/twiki/bin/view/M...|HTTP/1.1|     200| 3853|\n",
      "|64.242.88.10|     -|   -|07/Mar/2004:16:43...| GET|/twiki/bin/view/M...|HTTP/1.1|     200| 3686|\n",
      "|64.242.88.10|     -|   -|07/Mar/2004:16:45...| GET|/twiki/bin/attach...|HTTP/1.1|     401|12846|\n",
      "|64.242.88.10|     -|   -|07/Mar/2004:16:47...| GET|         /robots.txt|HTTP/1.1|     200|   68|\n",
      "|64.242.88.10|     -|   -|07/Mar/2004:16:47...| GET|/twiki/bin/rdiff/...|HTTP/1.1|     200| 5724|\n",
      "+------------+------+----+--------------------+----+--------------------+--------+--------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#hist_data = sqlContext.sql()\n",
    "dataDF = sqlContext.createDataFrame(parseLogFileRdd, schema=build_schema()).cache()\n",
    "dataDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|res_code|count|\n",
      "+--------+-----+\n",
      "|     200| 1272|\n",
      "|     401|  123|\n",
      "|     302|    6|\n",
      "|     404|    5|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "resCodeCntDf = dataDF.select('res_code').groupBy('res_code').count().orderBy(desc(\"count\"))\n",
    "resCodeCntDf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----------+-----------+\n",
      "|      avg_content|max_content|min_content|\n",
      "+-----------------+-----------+-----------+\n",
      "|7775.963726884779|       9812|          0|\n",
      "+-----------------+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate  content size .\n",
    "from pyspark.sql import functions as F\n",
    "contenDf = dataDF.select('size').agg(F.avg(dataDF.size).alias(\"avg_content\"),F.max(dataDF.size).alias(\"max_content\"),\n",
    "                                     F.min(dataDF.size).alias(\"min_content\"))\n",
    "contenDf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|                  ip|count|\n",
      "+--------------------+-----+\n",
      "|        64.242.88.10|  452|\n",
      "|          10.0.0.153|  188|\n",
      "|cr020r01-3.sac.ov...|   44|\n",
      "|h24-71-236-129.ca...|   36|\n",
      "|h24-70-69-74.ca.s...|   32|\n",
      "|market-mail.pandu...|   29|\n",
      "|ts04-ip92.hevanet...|   28|\n",
      "|ip68-228-43-49.tc...|   22|\n",
      "+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ipDf = dataDF.select('ip').groupBy('ip').count().orderBy(desc(\"count\")).where(col('count') >20)\n",
    "ipDf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
